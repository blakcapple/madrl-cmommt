# experience replay
batch_size: 64
mem_size: 1000000
# epsilon-greedy
eps_max: 1
eps_min: 0.05
gamma: 0.99
decay_frame: 300000
decay_rule: linear
# gradient clip
use_gradient_clip: True
gradient_clip: 10
# prioritized experience replay 
per: True
alpha: 0.5
beta: 0.4
# nstep learning
n_step: 3
# global config
warmup_step: 1000
train_step: 1500000
update_interval: 1
update_target_interval: 30000 
# hyper algo params
use_rnn: False
share_reward: True
use_global_info: False
# optim
lr: 0.00015
# network
hidden_dims: [256, 256]
cnn_kernel_size: 3
cnn_stride: 1
cnn_hidden_size: 64
cnn_use_ReLU: True
cnn_use_orthogonal: True
feature_dim: 256
emb_dim: 64
